# Purpose: Test flow "generate analysts then run interview for first analyst."
# How to run: Access notebook folder: `uv run python test.py`

import sys
sys.path.append('../..')

from langchain_core.messages import HumanMessage
from sub_graphs.generate_analysts.graph import graph as generate_analysts_graph
from sub_graphs.conduct_interview.graph import graph as conduct_interview_graph

# Input
max_analysts = 3
topic = "The benefits of adopting LangGraph as an agent framework"
thread = {
    "configurable": {
        "thread_id": "1"
    }
}

# Run the graph until the first interruption
for event in generate_analysts_graph.stream(
    {
        "topic": topic,
        "max_analysts": max_analysts,
    },
    thread,
    stream_mode="values"
):
    # Review
    analysts = event.get('analysts', '')
    if analysts:
        for analyst in analysts:
            print(f"Name: {analyst.name}")
            print(f"Affiliation: {analyst.affiliation}")
            print(f"Role: {analyst.role}")
            print(f"Description: {analyst.description}")
            print("-" * 50)

# SKIP HUMAN FEEDBACK NODE
# If we are satisfied, then we simply supply no feedback
further_feedback = None
generate_analysts_graph.update_state(
    thread,
    {
        "human_analyst_feedback": further_feedback
    },
    as_node="human_feedback"
)


# Continue the graph execution to end
for event in generate_analysts_graph.stream(None, thread, stream_mode="updates"):
    print("--Node--")
    node_name = next(iter(event.keys()))
    print(node_name)


final_state = generate_analysts_graph.get_state(thread)
analysts = final_state.values.get('analysts')

messages = [HumanMessage(f"So you said you were writing an article on {topic}?")]
thread = {"configurable": {"thread_id": "1"}}
interview = conduct_interview_graph.invoke(
    {
        "analyst": analysts[0],
        "messages": messages,
        "max_num_turns": 2
    },
    thread
)
print("interview: ", interview)
# Name: Dr. Emily Carter
# Affiliation: Tech Innovations Inc.
# Role: AI Framework Specialist
# Description: Dr. Carter focuses on the technical advantages of adopting LangGraph, emphasizing its scalability and integration capabilities with existing systems. She is motivated by the potential for LangGraph to enhance AI-driven solutions in various industries.
# --------------------------------------------------
# Name: Mr. James Liu
# Affiliation: Future of Work Research Group
# Role: Workplace Efficiency Analyst
# Description: Mr. Liu analyzes the impact of LangGraph on workplace productivity and collaboration. His interest lies in how the framework can streamline workflows and improve team dynamics, making it a valuable asset for organizations looking to optimize their operations.
# --------------------------------------------------
# Name: Dr. Sarah Thompson
# Affiliation: AI Ethics Consortium
# Role: Ethics and Compliance Advisor
# Description: Dr. Thompson examines the ethical implications of using LangGraph as an agent framework. She is concerned with data privacy, transparency, and the potential biases in AI systems, advocating for responsible adoption practices that prioritize ethical considerations.
# --------------------------------------------------
# interview:  {'messages': [HumanMessage(content='So you said you were writing an article on The benefits of adopting LangGraph as an agent framework?', additional_kwargs={}, response_metadata={}, id='5cc5540f-f90f-4751-9a35-9c4e9c51bd21'), AIMessage(content="Hello, Dr. Carter! My name is Alex, and I'm an analyst interested in exploring the benefits of adopting LangGraph as an agent framework. I’m eager to learn more about its technical advantages, particularly in terms of scalability and integration capabilities. \n\nTo start, could you share some specific examples of how LangGraph has demonstrated its scalability in real-world applications? What are some surprising insights you've encountered in this area?", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 241, 'total_tokens': 325, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-46094826-9ee6-4b3a-bd13-b7bf929a5d01-0', usage_metadata={'input_tokens': 241, 'output_tokens': 84, 'total_tokens': 325, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content="LangGraph offers significant scalability benefits for building and deploying AI applications. One of the key advantages is its ability to simplify the creation of sophisticated AI workflows through clear structures and dynamic state management. This allows developers to orchestrate multiple AI agents and LLM calls effectively, which is crucial for scaling applications that require complex reasoning and task execution.\n\nFor instance, LangGraph's Command feature reduces complexity by embedding routing decisions directly into node logic, making it easier to maintain and extend applications as they grow. This structured approach not only enhances the scalability of the applications but also improves debugging and iteration processes, allowing teams to respond quickly to changing requirements or issues that arise during development [1].\n\nMoreover, LangGraph's integration capabilities with existing systems are noteworthy. It provides an opinionated API for building agent-driven user experiences, which facilitates seamless integration with various data sources and external APIs. This flexibility is essential for organizations looking to enhance their AI-driven solutions across different industries, as it allows them to leverage their existing infrastructure while adopting new technologies [1][2].\n\nIn summary, LangGraph's scalability and integration capabilities make it a powerful framework for developing agentic applications that can grow and adapt to the evolving needs of businesses and users alike.\n\nSources:\n[1] https://www.langchain.com/langgraph\n[2] https://medium.com/collaborne-engineering/building-ai-agents-with-langgraph-19a2aa4e56b4", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 287, 'prompt_tokens': 2674, 'total_tokens': 2961, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, name='expert', id='run-54d0e44c-550d-4fa8-9b2a-5dc7e76688f1-0', usage_metadata={'input_tokens': 2674, 'output_tokens': 287, 'total_tokens': 2961, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content="That's fascinating, Dr. Carter! The structured approach and dynamic state management you mentioned seem to be game-changers for developers. Can you provide a specific case study or example where LangGraph's scalability significantly impacted a project? What were the challenges faced before adopting LangGraph, and how did it transform the outcome?", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 620, 'total_tokens': 683, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-faf30972-9703-4608-9a06-5fa2bb187415-0', usage_metadata={'input_tokens': 620, 'output_tokens': 63, 'total_tokens': 683, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Certainly! One notable case study involves a company that was developing a complex task automation application using traditional frameworks. They faced significant challenges with scalability, particularly as the number of tasks and the complexity of workflows increased. The existing system struggled to manage multiple agents and maintain context throughout lengthy interactions, leading to performance bottlenecks and difficulties in debugging.\n\nAfter adopting LangGraph, the company was able to leverage its graph-based orchestration and dynamic state management features. This allowed them to structure their workflows more clearly and manage the interactions between multiple agents effectively. The Command feature embedded routing decisions directly into the node logic, which simplified the overall architecture and reduced the complexity of the application.\n\nAs a result, the company experienced a dramatic improvement in scalability. They could now handle more tasks simultaneously without a drop in performance, and the ability to maintain context across interactions significantly enhanced the user experience. Additionally, the integrated developer studio provided tools for immediate debugging and iteration, which accelerated their development cycle and allowed them to respond quickly to user feedback.\n\nOverall, the transition to LangGraph not only resolved the scalability issues but also transformed their development process, enabling them to deliver a more robust and flexible application that met the evolving needs of their users [1][2].\n\nSources:\n[1] https://www.langchain.com/langgraph\n[2] https://medium.com/collaborne-engineering/building-ai-agents-with-langgraph-19a2aa4e56b4', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 290, 'prompt_tokens': 5034, 'total_tokens': 5324, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2304}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, name='expert', id='run-0b8ffa20-c72f-4abf-b072-c3069eef9f42-0', usage_metadata={'input_tokens': 5034, 'output_tokens': 290, 'total_tokens': 5324, 'input_token_details': {'audio': 0, 'cache_read': 2304}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'analyst': Analyst(affiliation='Tech Innovations Inc.', name='Dr. Emily Carter', role='AI Framework Specialist', description='Dr. Carter focuses on the technical advantages of adopting LangGraph, emphasizing its scalability and integration capabilities with existing systems. She is motivated by the potential for LangGraph to enhance AI-driven solutions in various industries.'), 'interview': "Human: So you said you were writing an article on The benefits of adopting LangGraph as an agent framework?\nAI: Hello, Dr. Carter! My name is Alex, and I'm an analyst interested in exploring the benefits of adopting LangGraph as an agent framework. I’m eager to learn more about its technical advantages, particularly in terms of scalability and integration capabilities. \n\nTo start, could you share some specific examples of how LangGraph has demonstrated its scalability in real-world applications? What are some surprising insights you've encountered in this area?\nAI: LangGraph offers significant scalability benefits for building and deploying AI applications. One of the key advantages is its ability to simplify the creation of sophisticated AI workflows through clear structures and dynamic state management. This allows developers to orchestrate multiple AI agents and LLM calls effectively, which is crucial for scaling applications that require complex reasoning and task execution.\n\nFor instance, LangGraph's Command feature reduces complexity by embedding routing decisions directly into node logic, making it easier to maintain and extend applications as they grow. This structured approach not only enhances the scalability of the applications but also improves debugging and iteration processes, allowing teams to respond quickly to changing requirements or issues that arise during development [1].\n\nMoreover, LangGraph's integration capabilities with existing systems are noteworthy. It provides an opinionated API for building agent-driven user experiences, which facilitates seamless integration with various data sources and external APIs. This flexibility is essential for organizations looking to enhance their AI-driven solutions across different industries, as it allows them to leverage their existing infrastructure while adopting new technologies [1][2].\n\nIn summary, LangGraph's scalability and integration capabilities make it a powerful framework for developing agentic applications that can grow and adapt to the evolving needs of businesses and users alike.\n\nSources:\n[1] https://www.langchain.com/langgraph\n[2] https://medium.com/collaborne-engineering/building-ai-agents-with-langgraph-19a2aa4e56b4\nAI: That's fascinating, Dr. Carter! The structured approach and dynamic state management you mentioned seem to be game-changers for developers. Can you provide a specific case study or example where LangGraph's scalability significantly impacted a project? What were the challenges faced before adopting LangGraph, and how did it transform the outcome?\nAI: Certainly! One notable case study involves a company that was developing a complex task automation application using traditional frameworks. They faced significant challenges with scalability, particularly as the number of tasks and the complexity of workflows increased. The existing system struggled to manage multiple agents and maintain context throughout lengthy interactions, leading to performance bottlenecks and difficulties in debugging.\n\nAfter adopting LangGraph, the company was able to leverage its graph-based orchestration and dynamic state management features. This allowed them to structure their workflows more clearly and manage the interactions between multiple agents effectively. The Command feature embedded routing decisions directly into the node logic, which simplified the overall architecture and reduced the complexity of the application.\n\nAs a result, the company experienced a dramatic improvement in scalability. They could now handle more tasks simultaneously without a drop in performance, and the ability to maintain context across interactions significantly enhanced the user experience. Additionally, the integrated developer studio provided tools for immediate debugging and iteration, which accelerated their development cycle and allowed them to respond quickly to user feedback.\n\nOverall, the transition to LangGraph not only resolved the scalability issues but also transformed their development process, enabling them to deliver a more robust and flexible application that met the evolving needs of their users [1][2].\n\nSources:\n[1] https://www.langchain.com/langgraph\n[2] https://medium.com/collaborne-engineering/building-ai-agents-with-langgraph-19a2aa4e56b4", 'context': ['<Document href="https://www.langchain.com/langgraph"/>\nBuild and scale agentic applications with LangGraph Platform. Design agent-driven user experiences with LangGraph Platform\'s APIs. Quickly deploy and scale your application with infrastructure built for agents. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that \'just work\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.” LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that \'just work\'. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\n</Document>\n\n---\n\n<Document href="https://medium.com/collaborne-engineering/building-ai-agents-with-langgraph-19a2aa4e56b4"/>\nLangGraph significantly simplifies building sophisticated AI workflows through clear structures, dynamic state management, and intuitive multi-agent orchestration. This post shares our learnings about LangGraph at NEXT, explain key concepts, and show you how to leverage its features — particularly dynamic states, edges, commands, and multi-agent collaboration — to build robust and flexible AI applications. LangGraph is a flexible, low-level workflow framework designed to orchestrate AI agents and LLM calls using graph-like structures: LangGraph’s Command simplifies this logic significantly, reducing complexity by embedding the routing decision directly into node logic. By structuring agents clearly with LangGraph, we significantly reduced complexity and improved our ability to maintain, extend, and debug AI features.\n</Document>\n\n---\n\n<Document href="https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/"/>\nThanks to its extensive set of tools and abstractions, developers may design powerful AI agents with complicated reasoning, task execution, and interaction with external data sources and APIs. Fundamentally, retaining context throughout lengthy talks, incorporating outside information, and coordinating multi-step projects are only a few of the difficulties developers encounter while collaborating with LLMs. LangChain tackles these issues. Generative AI| Large Language Models| Building LLM Applications using Prompt Engineering| Building Your first RAG System using LlamaIndex| Stability.AI| MidJourney| Building Production Ready RAG systems using LlamaIndex| Building LLMs for Code| Deep Learning| Python| Microsoft Excel| Machine Learning| Decision Trees| Pandas for Data Analysis| Ensemble Learning| NLP| NLP using Deep Learning| Neural Networks| Loan Prediction Practice Problem| Time Series Forecasting| Tableau| Business Analytics\n</Document>', '<Document source="https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence" page=""/>\nArtificial intelligence (AI) has been used in applications throughout industry and academia. In a manner analogous to electricity or computers, AI serves as a general-purpose technology. AI programs are designed to simulate human perception and understanding. These systems are capable of adapting to new information and responding to changing situations. Machine learning has been used for various scientific and commercial purposes including language translation, image recognition, decision-making, credit scoring, and e-commerce.\n\n\n== Internet and e-commerce ==\n\n\n=== Web feeds and posts ===\nMachine learning has been used for recommendation systems in determining which posts should show up in social media feeds. Various types of social media analysis also make use of machine learning and there is research into its use for (semi-)automated tagging/enhancement/correction of online misinformation and related filter bubbles.\nAI has been used to customize shopping options and personalize offers. Online gambling companies have used AI for targeting gamblers.\n\n\n=== Virtual assistants and search ===\n\nIntelligent personal assistants use AI to understand many natural language requests in other ways than rudimentary commands. Common examples are Apple\'s Siri, Amazon\'s Alexa, and a more recent AI, ChatGPT by OpenAI.\nBing Chat has used artificial intelligence as part of its search engine.\n\n\n=== Spam filtering ===\n\nMachine learning can be used to combat spam, scams, and phishing. It can scrutinize the contents of spam and phishing attacks to attempt to identify malicious elements. Some models built via machine learning algorithms have over 90% accuracy in distinguishing between spam and legitimate emails. These models can be refined using new data and evolving spam tactics. Machine learning also analyzes traits such as sender behavior, email header information, and attachment types, potentially enhancing spam detection.\n\n\n=== Language translation ===\n\nSpeech translation technology attempts to convert one language\'s spoken words into another language. This potentially reduces language barriers in global commerce and cross-cultural exchange, enabling speakers of various languages to communicate with one another. \nAI has been used to automatically translate spoken language and textual content in products such as Microsoft Translator, Google Translate, and DeepL Translator. Additionally, research and development are in progress to decode and conduct animal communication.\nMeaning is conveyed not only by text, but also through usage and context (see semantics and pragmatics). As a result, the two primary categorization approaches for machine translations are statistical machine translation (SMT) and neural machine translations (NMTs). The old method of performing translation was to use statistical methodology to forecast the best probable output with specific algorithms. However, with NMT, the approach employs dynamic algorithms to achieve better translations based on context.\n\n\n=== Facial recognition and image labeling ===\n\nAI has been used in facial recognition systems. Some examples are Apple\'s Face ID and Android\'s Face Unlock, which are used to secure mobile devices.\nImage labeling has been used by Google Image Labeler to detect products in photos and to allow people to search based on a photo. Image labeling has also been demonstrated to generate speech to describe images to blind people. Facebook\'s DeepFace identifies human faces in digital images.\n\n\n== Games and entertainment ==\n\nGames have been a major application of AI\'s capabilities since the 1950s. In the 21st century, AIs have beaten human players in many games, including chess (Deep Blue), Jeopardy! (Watson), Go (AlphaGo), poker (Pluribus and Cepheus), E-sports (StarCraft), and general game playing (AlphaZero and MuZero).\nKuki AI is a set of chatbots and other apps which were designed for entertainment and as a marketing tool. Character.ai is another example of a chatbot being used for\n</Document>\n\n---\n\n<Document source="https://en.wikipedia.org/wiki/Semantic_Web" page=""/>\nThe Semantic Web, sometimes known as Web 3.0 (not to be confused with Web3), is an extension of the World Wide Web through standards set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.\nTo enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF) and Web Ontology Language (OWL) are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.\nThese standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, "The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries." The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.\n\n\n== History ==\nThe term was coined by Tim Berners-Lee for a web of data (or data web) that can be processed by machines—that is, one in which much of the meaning is machine-readable. While its critics have questioned its feasibility, proponents argue that applications in library and information science, industry, biology and human sciences research have already proven the validity of the original concept.\nBerners-Lee originally expressed his vision of the Semantic Web in 1999 as follows:\n\nI have a dream for the Web [in which computers] become capable of analyzing all the data on the Web – the content, links, and transactions between people and computers. A "Semantic Web", which makes this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy and our daily lives will be handled by machines talking to machines. The "intelligent agents" people have touted for ages will finally materialize.\nThe 2001 Scientific American article by Berners-Lee, Hendler, and Lassila described an expected evolution of the existing Web to a Semantic Web. In 2006, Berners-Lee and colleagues stated that: "This simple idea…remains largely unrealized".\nIn 2013, more than four million Web domains (out of roughly 250 million total) contained Semantic Web markup.\n\n\n== Example ==\nIn the following example, the text "Paul Schuster was born in Dresden" on a website will be annotated, connecting a person with their place of birth. The following HTML fragment shows how a small graph is being described, in RDFa-syntax using a schema.org vocabulary and a Wikidata ID:\n\nThe example defines the following five triples (shown in Turtle syntax). Each triple represents one edge in the resulting graph: the first element of the triple (the subject) is the name of the node where the edge starts, the second element (the predicate) the type of the edge, and the last and third element (the object) either the name of the node where the edge ends or a literal value (e.g. a text, a number, etc.).\n\nThe triples result in the graph shown in the given figure.\n\nOne of the advantages of using Uniform Resource Identifiers (URIs) is that they can be dereferenced using the HTTP protocol. According to the so-called Linked Open Data principles, such a dereferenced URI should result in a document that offers further data about the given URI. In this example, all URIs, both for edges and nodes (e.g. http://schema.org/Person, http://schema.org/birthPlace, http://www.wikidata.org/entity/Q1731) can be dereferenced and will result in further RDF graphs, describing the URI, e.g. that Dresden is a city in Germany, or that a person, in the sense of that URI, can be fictional.\nThe second graph shows the previous example, but now enriched with a few of the triples from the documents that result from dereferencing https://schema.org/Person (green edge) and https://www.wikidata.org/entity/Q1731 (blue \n</Document>', '<Document href="https://medium.com/@dmitri.mahayana/chain-everything-with-langgraph-9a0f35b2d7a2"/>\nScalability: LangGraph is highly scalable, making it suitable for complex applications with multiple stages, branches, and data flows. Use Case.\n</Document>\n\n---\n\n<Document href="https://www.langchain.com/langgraph"/>\nBuild and scale agentic applications with LangGraph Platform. Design agent-driven user experiences with LangGraph Platform\'s APIs. Quickly deploy and scale your application with infrastructure built for agents. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that \'just work\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.” LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that \'just work\'. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\n</Document>\n\n---\n\n<Document href="https://www.getzep.com/ai-agents/langchain-agents-langgraph"/>\nLangGraph handles complex workflows through graph-based orchestration, persistent state management, and multi-agent coordination, making it better suited for advanced applications. | LangGraph features | Supports graph-based workflows for dynamic decision-making, cyclical graphs for iterative processes, persistent state management, and integration with LangChain and LangSmith for monitoring and optimization. Building a single-agent workflow in LangGraph is straightforward and demonstrates the core concepts of the framework, such as state management and graph-based workflows. CHAPTER 2 LangGraph Tutorial: Building Agents with LangChain\'s Agent Framework Learn how LangGraph, an AI agent framework built by LangChain, allows developers to create complex and flexible agent workflows using stateful graphs and built-in memory management.\n</Document>', '<Document source="https://en.wikipedia.org/wiki/Data_lineage" page=""/>\nData lineage refers to the process of tracking how data is generated, transformed, transmitted and used across a system over time. It documents data\'s origins, transformations and movements, providing detailed visibility into its life cycle. This process simplifies the identification of errors in data analytics workflows, by enabling users to trace issues back to their root causes.\nData lineage facilitates the ability to replay specific segments or inputs of the dataflow. This can be used in debugging or regenerating lost outputs. In database systems, this concept is closely related to data provenance, which involves maintaining records of inputs, entities, systems and processes that influence data.\nData provenance provides a historical record of data origins and transformations. It supports forensic activities such as data-dependency analysis, error/compromise detection, recovery, auditing and compliance analysis: "Lineage is a simple type of why provenance."\nData governance plays a critical role in managing metadata by establishing guidelines, strategies and policies. Enhancing data lineage with data quality measures and master data management adds business value. Although data lineage is typically represented through a graphical user interface (GUI), the methods for gathering and exposing metadata to this interface can vary. Based on the metadata collection approach, data lineage can be categorized into three types: Those involving software packages for structured data, programming languages and Big data systems.\nData lineage information includes technical metadata about data transformations. Enriched data lineage may include additional elements such as data quality test results, reference data, data models, business terminology, data stewardship information, program management details and enterprise systems associated with data points and transformations. Data lineage visualization tools often include masking features that allow users to focus on information relevant to specific use cases. To unify representations across disparate systems, metadata normalization or standardization may be required.\n\n\n== Representation of data lineage ==\nRepresentation broadly depends on the scope of the metadata management and reference point of interest. Data lineage provides sources of the data and intermediate data flow hops from the reference point with backward data lineage, leading to the final destination\'s data points and its intermediate data flows with forward data lineage. These views can be combined with end-to-end lineage for a reference point that provides a complete audit trail of that data point of interest from sources to their final destinations. As the data points or hops increase, the complexity of such representation becomes incomprehensible. Thus, the best feature of the data lineage view is the ability to simplify the view by temporarily masking unwanted peripheral data points. Tools with the masking feature enable scalability of the view and enhance analysis with the best user experience for both technical and business users. Data lineage also enables companies to trace sources of specific business data to track errors, implement changes in processes and implementing system migrations to save significant amounts of time and resources. Data lineage can improve efficiency in business intelligence BI processes.\nData lineage can be represented visually to discover the data flow and movement from its source to destination via various changes and hops on its way in the enterprise environment. This includes how the data is transformed along the way, how the representation and parameters change and how the data splits or converges after each hop. A simple representation of the Data Lineage can be shown with dots and lines, where dots represent data containers for data points, and lines connecting them represent transformations the data undergoes between the data containers. \nData lineage can be visualized at various levels b\n</Document>\n\n---\n\n<Document source="https://en.wikipedia.org/wiki/COVID-19_pandemic" page=""/>\nThe COVID-19 pandemic (also known as the coronavirus pandemic and COVID pandemic), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), began with an outbreak of COVID-19 in Wuhan, China, in December 2019. Soon after, it spread to other areas of Asia, and then worldwide in early 2020. The World Health Organization (WHO) declared the outbreak a public health emergency of international concern (PHEIC) on 30 January 2020, and assessed the outbreak as having become a pandemic on 11 March.\nCOVID-19 symptoms range from asymptomatic to deadly, but most commonly include fever, sore throat, nocturnal cough, and fatigue. Transmission of the virus is often through airborne particles. Mutations have produced many strains (variants) with varying degrees of infectivity and virulence. COVID-19 vaccines were developed rapidly and deployed to the general public beginning in December 2020, made available through government and international programmes such as COVAX, aiming to provide vaccine equity. Treatments include novel antiviral drugs and symptom control. Common mitigation measures during the public health emergency included travel restrictions, lockdowns, business restrictions and closures, workplace hazard controls, mask mandates, quarantines, testing systems, and contact tracing of the infected.\nThe pandemic caused severe social and economic disruption around the world, including the largest global recession since the Great Depression. Widespread supply shortages, including food shortages, were caused by supply chain disruptions and panic buying. Reduced human activity led to an unprecedented temporary decrease in pollution. Educational institutions and public areas were partially or fully closed in many jurisdictions, and many events were cancelled or postponed during 2020 and 2021. Telework became much more common for white-collar workers as the pandemic evolved. Misinformation circulated through social media and mass media, and political tensions intensified. The pandemic raised issues of racial and geographic discrimination, health equity, and the balance between public health imperatives and individual rights.\nThe WHO ended the PHEIC for COVID-19 on 5 May 2023. The disease has continued to circulate. However, as of 2024, experts were uncertain as to whether it was still a pandemic. Pandemics and their ends are not well-defined, and whether or not one has ended differs according to the definition used. As of 9 March 2025, COVID-19 has caused 7,090,763 confirmed deaths, and 18.2 to 33.5 million estimated deaths. The COVID-19 pandemic ranks as the fifth-deadliest pandemic or epidemic in history.\n\n\n== Terminology ==\n\n\n=== Pandemic ===\nIn epidemiology, a pandemic is defined as "an epidemic occurring over a very wide area, crossing international boundaries, and usually affecting a large number of people". During the COVID-19 pandemic, as with other pandemics, the meaning of this term has been challenged.\nThe end of a pandemic or other epidemic only rarely involves the total disappearance of a disease, and historically, much less attention has been given to defining the ends of epidemics than their beginnings. The ends of particular epidemics have been defined in a variety of ways, differing according to academic field, and differently based on location and social group. An epidemic\'s end can be considered a social phenomenon, not just a biological one.\nTime reported in March 2024 that expert opinions differ on whether or not COVID-19 is currently considered endemic or pandemic, and that the WHO continued to call the disease a pandemic on its website.\n\n\n=== Virus names ===\nDuring the initial outbreak in Wuhan, the virus and disease were commonly referred to as "coronavirus", "Wuhan coronavirus", "the coronavirus outbreak" and the "Wuhan coronavirus outbreak", with the disease sometimes called "Wuhan pneumonia". In January 2020, the WHO recommended 2019-nCoV and 2019-nCoV acute respiratory disease as interim names for th\n</Document>'], 'max_num_turns': 2}