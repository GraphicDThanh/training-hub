{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to stream\n",
    "- https://langchain-ai.github.io/langgraph/how-tos/streaming/\n",
    "\n",
    "`graph.stream(..., stream_mode=<stream_mode>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "\n",
    "\n",
    "def refine_topic(state: State):\n",
    "    return {\"topic\": state[\"topic\"] + \" and cats\"}\n",
    "\n",
    "\n",
    "def generate_joke(state: State):\n",
    "    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n",
    "\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(refine_topic)\n",
    "    .add_node(generate_joke)\n",
    "    .add_edge(START, \"refine_topic\")\n",
    "    .add_edge(\"refine_topic\", \"generate_joke\")\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream all values in state with `stream_mode=\"values\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'ice cream'}\n",
      "{'topic': 'ice cream and cats'}\n",
      "{'topic': 'ice cream and cats', 'joke': 'This is a joke about ice cream and cats'}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream state updates from nodes with `stream_mode=\"updates\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refine_topic': {'topic': 'ice cream and cats'}}\n",
      "{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream debug events with `stream_mode=\"debug\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'task', 'timestamp': '2025-03-04T08:12:00.302236+00:00', 'step': 1, 'payload': {'id': 'a60ef441-2164-7f96-f8ef-c28ed0dec121', 'name': 'refine_topic', 'input': {'topic': 'ice cream'}, 'triggers': ['start:refine_topic']}}\n",
      "{'type': 'task_result', 'timestamp': '2025-03-04T08:12:00.302469+00:00', 'step': 1, 'payload': {'id': 'a60ef441-2164-7f96-f8ef-c28ed0dec121', 'name': 'refine_topic', 'error': None, 'result': [('topic', 'ice cream and cats')], 'interrupts': []}}\n",
      "{'type': 'task', 'timestamp': '2025-03-04T08:12:00.302632+00:00', 'step': 2, 'payload': {'id': 'f71b9045-5936-ae30-4b9c-33895562fa10', 'name': 'generate_joke', 'input': {'topic': 'ice cream and cats'}, 'triggers': ['refine_topic']}}\n",
      "{'type': 'task_result', 'timestamp': '2025-03-04T08:12:00.302793+00:00', 'step': 2, 'payload': {'id': 'f71b9045-5936-ae30-4b9c-33895562fa10', 'name': 'generate_joke', 'error': None, 'result': [('joke', 'This is a joke about ice cream and cats')], 'interrupts': []}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"debug\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream LLM tokens with `stream_mode=\"messages\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def generate_joke(state: State):\n",
    "    llm_response = llm.invoke([{\"role\": \"user\", \"content\": f\"Generate a joke about {state['topic']}\"}])\n",
    "    return {\"joke\": llm_response.content}\n",
    "\n",
    "graph =  (\n",
    "    StateGraph(State)\n",
    "    .add_node(refine_topic)\n",
    "    .add_node(generate_joke)\n",
    "    .add_edge(START, \"refine_topic\")\n",
    "    .add_edge(\"refine_topic\", \"generate_joke\")\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why| did| the| cat| sit| on| the| ice| cream| cone|?\n",
      "\n",
      "|Because| it| wanted| to| be| a| p|urr|-f|ect| scoop|!| |"
     ]
    }
   ],
   "source": [
    "for message_chunk, metadata in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if message_chunk.content:\n",
    "        print(message_chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'langgraph_step': 2,\n",
       " 'langgraph_node': 'generate_joke',\n",
       " 'langgraph_triggers': ['refine_topic'],\n",
       " 'langgraph_path': ('__pregel_pull', 'generate_joke'),\n",
       " 'langgraph_checkpoint_ns': 'generate_joke:a35ee441-d055-5cbc-9272-87755f134ba3',\n",
       " 'checkpoint_ns': 'generate_joke:a35ee441-d055-5cbc-9272-87755f134ba3',\n",
       " 'ls_provider': 'openai',\n",
       " 'ls_model_name': 'gpt-4o-mini',\n",
       " 'ls_model_type': 'chat',\n",
       " 'ls_temperature': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream custom data with `stream_mode=\"custom\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import StreamWriter\n",
    "\n",
    "def generate_joke(state: State, writer: StreamWriter):\n",
    "    writer({\"custom_key\": \"Writing custom data while generating a joke\"})\n",
    "    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(refine_topic)\n",
    "    .add_node(generate_joke)\n",
    "    .add_edge(START, \"refine_topic\")\n",
    "    .add_edge(\"refine_topic\", \"generate_joke\")\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_key': 'Writing custom data while generating a joke'}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"topic\": \"ice cream\"}, stream_mode=\"custom\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure multiple streaming modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream mode: updates\n",
      "{'refine_topic': {'topic': 'ice cream and cats'}}\n",
      "\n",
      "\n",
      "Stream mode: custom\n",
      "{'custom_key': 'Writing custom data while generating a joke'}\n",
      "\n",
      "\n",
      "Stream mode: updates\n",
      "{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for stream_mode, chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "):\n",
    "    print(f\"Stream mode: {stream_mode}\")\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
