{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to stream LLM tokens from your graph\n",
    "- https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/\n",
    "- `graph.stream(..., stream_mode=\"messages\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import START, StateGraph, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "joke_model = ChatOpenAI(model=\"gpt-4o-mini\", tags=[\"joke\"])\n",
    "poem_model = ChatOpenAI(model=\"gpt-4o-mini\", tags=[\"poem\"])\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    poem: str\n",
    "\n",
    "\n",
    "async def call_model(state, config):\n",
    "    topic = state[\"topic\"]\n",
    "    print(\"Writing joke...\")\n",
    "    joke_response = await joke_model.ainvoke(\n",
    "        [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n",
    "        config\n",
    "    )\n",
    "    print(\"\\n\\nWriting poem...\")\n",
    "    poem_response = await poem_model.ainvoke(\n",
    "        [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}],\n",
    "        config\n",
    "    )\n",
    "    return {\"joke\": joke_response.content, \"poem\": poem_response.content}\n",
    "\n",
    "\n",
    "graph = StateGraph(State).add_node(call_model).add_edge(START, \"call_model\").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing joke...\n",
      "Why| did| the| cat| sit| on| the| computer|?| \n",
      "\n",
      "|Because| it| wanted| to| keep| an| eye| on| the| mouse|!|\n",
      "\n",
      "Writing poem...\n",
      "In| shadows| sleek|,| where| silence| p|urr|s|,|  \n",
      "|Soft| whispers| dance| in| twilight|'s| bl|urs|.|  \n",
      "|With| eyes| like| moons| that| softly| gle|am|,|  \n",
      "|They| float| through| dreams|,| a| dusk|-lit| dream|.|  \n",
      "\n",
      "|Wh|isk|ers| twitch| at| secrets| held|,|  \n",
      "|In| sun|lit| spots|,| their| warmth| rep|elled|.|  \n",
      "|A| gentle| leap|,| a| playful| dart|,|  \n",
      "|Each| cat| a| keeper| of| the| heart|.|  \n",
      "\n",
      "|With| velvet| paws| on| padded| floors|,|  \n",
      "|They| claim| the| night|,| then| seek| the| doors|.|  \n",
      "|In| every| curl| and| playful| sw|at|,|  \n",
      "|A| world| of| magic|,| they| have| sought|.|  \n",
      "\n",
      "|So| here|â€™s| to| cats|,| both| wild| and| wise|,|  \n",
      "|With| every| p|urr|,| they| mesmer|ize|.|  \n",
      "|In| their| quiet| grace|,| we| find| our| way|,|  \n",
      "|Our| furry| friends|,| by| night| and| day|.|  |"
     ]
    }
   ],
   "source": [
    "async for msg, metadata in graph.astream(\n",
    "    {\"topic\": \"cats\"},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if msg.content:\n",
    "        print(msg.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'langgraph_step': 1,\n",
       " 'langgraph_node': 'call_model',\n",
       " 'langgraph_triggers': ['start:call_model'],\n",
       " 'langgraph_path': ('__pregel_pull', 'call_model'),\n",
       " 'langgraph_checkpoint_ns': 'call_model:0ebb5c41-ff2a-2c71-c231-f6e9c44d53cb',\n",
       " 'checkpoint_ns': 'call_model:0ebb5c41-ff2a-2c71-c231-f6e9c44d53cb',\n",
       " 'ls_provider': 'openai',\n",
       " 'ls_model_name': 'gpt-4o-mini',\n",
       " 'ls_model_type': 'chat',\n",
       " 'ls_temperature': None,\n",
       " 'tags': ['poem']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to specific LLM invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing joke...\n",
      "Why| was| the| cat| sitting| on| the| computer|?\n",
      "\n",
      "|Because| it| wanted| to| keep| an| eye| on| the| mouse|!|\n",
      "\n",
      "Writing poem...\n"
     ]
    }
   ],
   "source": [
    "async for msg, metadata in graph.astream(\n",
    "    {\"topic\": \"cats\"},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if msg.content and \"joke\" in metadata.get(\"tags\", []):\n",
    "        print(msg.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example without LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "openai_client = AsyncOpenAI()\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "async def stream_tokens(model_name: str, messages: list[dict]):\n",
    "    response = await openai_client.chat.completions.create(\n",
    "        messages=messages, model=model_name, stream=True\n",
    "    )\n",
    "    role = None\n",
    "\n",
    "    async for chunk in response:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta.role is not None:\n",
    "            role = delta.role\n",
    "\n",
    "        if delta.content:\n",
    "            yield {\"role\": role, \"content\": delta.content}\n",
    "\n",
    "\n",
    "async def call_model(state, config, writer):\n",
    "    topic = state[\"topic\"]\n",
    "    joke = \"\"\n",
    "    poem = \"\"\n",
    "\n",
    "    print(\"Writing joke...\")\n",
    "    async for msg_chunk in stream_tokens(\n",
    "        model_name, [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}]\n",
    "    ):\n",
    "        joke += msg_chunk[\"content\"]\n",
    "        metadata = {**config[\"metadata\"], \"tags\": [\"joke\"]}\n",
    "        chunk_to_stream = (msg_chunk, metadata)\n",
    "        writer(chunk_to_stream)\n",
    "\n",
    "    print(\"\\n\\nWriting poem...\")\n",
    "    async for msg_chunk in stream_tokens(\n",
    "        model_name, [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}]\n",
    "    ):\n",
    "        poem += msg_chunk[\"content\"]\n",
    "        metadata = {**config[\"metadata\"], \"tags\": [\"poem\"]}\n",
    "        chunk_to_stream = (msg_chunk, metadata)\n",
    "        writer(chunk_to_stream)\n",
    "\n",
    "\n",
    "    return {\"joke\": joke, \"poem\": poem}\n",
    "\n",
    "\n",
    "graph = StateGraph(State).add_node(call_model).add_edge(START, \"call_model\").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing joke...\n",
      "Why| did| the| cat| sit| on| the| computer|?\n",
      "\n",
      "|Because| it| wanted| to| keep| an| eye| on| the| mouse|!|\n",
      "\n",
      "Writing poem...\n",
      "In| shadows| soft|,| they| weave| and| glide|,|  \n",
      "|Wh|isk|ered| whispers|,| playful| pride|.|  \n",
      "|With| emerald| eyes| like| twilight| skies|,|  \n",
      "|In| every| p|ounce|,| a| secret| lies|.|  \n",
      "\n",
      "|N|im|ble| dancers|,| sleek| and| spr|y|,|  \n",
      "|Ch|asing| dreams| as| moon|be|ams| fly|.|  \n",
      "|Cur|led| in| warmth|,| in| sun|lit| spots|,|  \n",
      "|In| their| still|ness|,| time| forget|s|.|  \n",
      "\n",
      "|M|yster|ious| minds|,| both| wise| and| sly|,|  \n",
      "|Comp|an|ions| close|,| yet| free| to| fly|.|  \n",
      "|In| rhythmic| p|urr|s|,| they| claim| their| throne|,|  \n",
      "|In| every| heart|,| a| cat| makes| home|.|  |"
     ]
    }
   ],
   "source": [
    "async for msg, metadata in graph.astream(\n",
    "    {\"topic\": \"cats\"},\n",
    "    stream_mode=\"custom\"\n",
    "):\n",
    "    print(msg[\"content\"], end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'langgraph_step': 1,\n",
       " 'langgraph_node': 'call_model',\n",
       " 'langgraph_triggers': ['start:call_model'],\n",
       " 'langgraph_path': ('__pregel_pull', 'call_model'),\n",
       " 'langgraph_checkpoint_ns': 'call_model:6b812dc0-390c-c6db-5435-7a23ffa19f95',\n",
       " 'tags': ['poem']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing joke...\n",
      "\n",
      "\n",
      "Writing poem...\n",
      "In| shadows| soft|,| where| whispers| dwell|,|  \n",
      "|A| feline| grace|,| a| myst|ic| spell|.|  \n",
      "|With| emerald| eyes| and| nim|ble| paws|,|  \n",
      "|They| weave| through| dreams|,| without| a| pause|.|  \n",
      "\n",
      "|On| sun|be|ams| bright|,| they| stretch| and| y|awn|,|  \n",
      "|A| sym|phony| of| p|urr|s| at| dawn|.|  \n",
      "|With| playful| leaps| and| silent| tread|,|  \n",
      "|They| reign| the| night|,| their| kingdom| spread|.|  \n",
      "\n",
      "|Oh|,| curious| hearts|,| with| spirits| free|,|  \n",
      "|In| every| p|ounce|,| a| glimpse| of| g|lee|.|  \n",
      "|For| in| their| gaze|,| the| world's| a| stage|,|  \n",
      "|Each| whisk|ered| tale|,| a| timeless| page|.|  |"
     ]
    }
   ],
   "source": [
    "async for msg, metadata in graph.astream(\n",
    "    {\"topic\": \"cats\"},\n",
    "    stream_mode=\"custom\",\n",
    "):\n",
    "    if \"poem\" in metadata.get(\"tags\", []):\n",
    "        print(msg[\"content\"], end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
